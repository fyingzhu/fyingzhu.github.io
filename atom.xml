<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>fyingzhu&#39;s Blog</title>
  
  <subtitle>分享知识,收获快乐,总结自我</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://fyingzhu.com/"/>
  <updated>2018-03-01T03:01:28.695Z</updated>
  <id>http://fyingzhu.com/</id>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>kaggle系列之Machine Learning</title>
    <link href="http://fyingzhu.com/2018/03/01/kaggle%E7%B3%BB%E5%88%97%E4%B9%8BMachine-Learning/"/>
    <id>http://fyingzhu.com/2018/03/01/kaggle系列之Machine-Learning/</id>
    <published>2018-03-01T02:51:53.000Z</published>
    <updated>2018-03-01T03:01:28.695Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本系列是<a href="https://www.kaggle.com/learn/overview" target="_blank" rel="noopener">kaggle learn</a>中的内容，学习并记录之。</p></blockquote><a id="more"></a>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本系列是&lt;a href=&quot;https://www.kaggle.com/learn/overview&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;kaggle learn&lt;/a&gt;中的内容，学习并记录之。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="kaggle" scheme="http://fyingzhu.com/categories/kaggle/"/>
    
    
      <category term="learn" scheme="http://fyingzhu.com/tags/learn/"/>
    
  </entry>
  
  <entry>
    <title>ubuntu16.04 + NVIDIA驱动 + CUDA + CUDA + tensorflow-gpu + keras安装</title>
    <link href="http://fyingzhu.com/2018/01/30/ubuntu16.04%20+%20NVIDIA%E9%A9%B1%E5%8A%A8%20+%20CUDA%20+%20CUDA%20+%20tensorflow-gpu%20+%20keras%E5%AE%89%E8%A3%85/"/>
    <id>http://fyingzhu.com/2018/01/30/ubuntu16.04 + NVIDIA驱动 + CUDA + CUDA + tensorflow-gpu + keras安装/</id>
    <published>2018-01-30T08:34:00.000Z</published>
    <updated>2018-01-31T06:36:59.395Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://github.com/fyingzhu/Markdown_photo/blob/master/blog/20180130001.jpg?raw=true" alt=""></p><ul><li><font color="red">写在前面，一路安装走来，遇到很多TensorFlow、cuda、cudnn版本不兼容匹配的，后来，我找到了<a href="https://www.nvidia.com/en-us/data-center/gpu-accelerated-applications/tensorflow/" target="_blank" rel="noopener">NVIDIA官方系统配置</a> ，可以按照这个来配置，避免多走弯路。</font></li></ul><hr><p><strong>环境：</strong></p><ul><li>ubuntu 16.04 64bit</li><li><p>显卡：NVIDIA Tesla k40m + 集成显卡</p><blockquote><p>注：在<a href="http://www.nvidia.com/Download/index.aspx?lang=en-us" target="_blank" rel="noopener">NVIDIA DriverDownloads</a>查找的最新为384.66，系统配置如下：<br><img src="https://github.com/fyingzhu/Markdown_photo/blob/master/InstallTool/2018013001.jpg?raw=true" alt="系统配置"></p><font color="red"> 但是，安装不成功！后选择375.66成功</font></blockquote></li><li><p>驱动：nvidia 375.66</p></li><li>软件：cuda8.0 + cuDNN5.1</li></ul><a id="more"></a><h2 id="1-准备工作："><a href="#1-准备工作：" class="headerlink" title="1.准备工作："></a>1.准备工作：</h2><h3 id="1-1-配置安装环境"><a href="#1-1-配置安装环境" class="headerlink" title="1.1 配置安装环境"></a>1.1 配置安装环境</h3><p>若不安装第5步 tensorflow-gpu+keras，此处可省略。。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install python-dev python-pip python-nose gcc g++ git gfortran</span><br><span class="line">sudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compiler</span><br><span class="line">sudo apt-get install --no-install-recommends libboost-all-dev</span><br><span class="line">sudo apt-get install libopenblas-dev liblapack-dev libatlas-base-dev</span><br><span class="line">sudo apt-get install libgflags-dev libgoogle-glog-dev liblmdb-dev</span><br><span class="line">sudo apt-get install git cmake build-essential</span><br></pre></td></tr></table></figure></p><h3 id="1-2-禁用自带的显卡驱动nouveau"><a href="#1-2-禁用自带的显卡驱动nouveau" class="headerlink" title="1.2 禁用自带的显卡驱动nouveau"></a>1.2 禁用自带的显卡驱动nouveau</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo gedit /etc/modprobe.d/blacklist-nouveau.conf</span><br></pre></td></tr></table></figure><p>在其中加入：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">blacklist nouveau option nouveau modeset=0</span><br></pre></td></tr></table></figure></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo update-initramfs -u</span><br></pre></td></tr></table></figure><h3 id="1-3-加入环境变量"><a href="#1-3-加入环境变量" class="headerlink" title="1.3 加入环境变量"></a>1.3 加入环境变量</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo gedit ~/.bashrc</span><br></pre></td></tr></table></figure><p>在其中加入：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH</span><br><span class="line">export LD_LIBRARY_PATH=/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH</span><br></pre></td></tr></table></figure></p><p>执行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source ~/.bashrc</span><br></pre></td></tr></table></figure></p><h2 id="2-安装NVIDIA显卡驱动"><a href="#2-安装NVIDIA显卡驱动" class="headerlink" title="2. 安装NVIDIA显卡驱动"></a>2. 安装NVIDIA显卡驱动</h2><p>首先还是先去官网下载正确的显卡驱动，官网：<a href="http://www.geforce.cn/drivers" target="_blank" rel="noopener">http://www.geforce.cn/drivers</a><br>查看自己的显卡型号：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo lshw -numeric -C display</span><br></pre></td></tr></table></figure></p><p>如果之前安装过nvidia驱动，先卸载：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get remove --purge nvidia-*</span><br></pre></td></tr></table></figure></p><p>Ctrl-Alt+F1 进入命令行界面<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd Downloads</span><br><span class="line"></span><br><span class="line">sudo /etc/init.d/lightdm stop #关闭当前图形环境令</span><br><span class="line"></span><br><span class="line">sudo chmod a+x NVIDIA-Linux-x86_64-375.66.run #给驱动run文件赋予执行权限</span><br><span class="line"></span><br><span class="line">sudo ./NVIDIA-Linux-x86_64-375.66.run --no-x-check</span><br><span class="line">--no-nouveau-check --no-opengl-files  # 这句一定要加参数，不然就会循环登录。</span><br></pre></td></tr></table></figure></p><blockquote><p>如果进入循环登录，要再次Ctrl-Alt+F1 进入命令行界面，卸载驱动：<br>sudo apt-get remove –purge nvidia-*</p></blockquote><ul><li>–no-opengl-files  只安装驱动文件，不安装OpenGL文件。这个参数最重要</li><li>–no-check 安装驱动时不检查X服务</li><li>–no-nouveau-check 安装驱动时不检查nouveau </li></ul><p>后面两个参数可不加(Ps: 没懂 - 与 - - 的区别，貌似都可以，我上面写的是两个- -哦)。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo /etc/init.d/lightdm start #重新启动图形环境</span><br><span class="line"></span><br><span class="line">reboot</span><br></pre></td></tr></table></figure></p><h2 id="3-安装cuda"><a href="#3-安装cuda" class="headerlink" title="3. 安装cuda"></a>3. 安装cuda</h2><p>去官网下载：<a href="https://developer.nvidia.com/cuda-downloads" target="_blank" rel="noopener">https://developer.nvidia.com/cuda-downloads</a></p><p>注意一定要下载runfile。</p><p>Ctrl-Alt+F1 进入命令行界面<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cd Downloads</span><br><span class="line"></span><br><span class="line">sudo service lightdm stop #禁用X服务</span><br><span class="line">sudo /etc/init.d/lightdm stop #一样的命令</span><br><span class="line"></span><br><span class="line">sudo sh cuda-8.0.44_linux.run --no-opengl-libs</span><br></pre></td></tr></table></figure></p><p>注：第一条问是否安装nvidia驱动，选择no，后面一直输入yes就行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo /etc/init.d/lightdm start #启用服务</span><br><span class="line"></span><br><span class="line">reboot</span><br></pre></td></tr></table></figure></p><p>重启之后进入修改环境配置<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo gedit ~/.bashrc</span><br></pre></td></tr></table></figure></p><p>加入：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export PATH=/usr/local/cuda-8.0/bin:$PATH</span><br><span class="line">export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH</span><br></pre></td></tr></table></figure></p><p>执行：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source ~/.bashrc</span><br></pre></td></tr></table></figure></p><p>测试安装是否成功：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/cuda-8.0/samples/1_Utilities/deviceQuery</span><br><span class="line"></span><br><span class="line">sudo make</span><br><span class="line"></span><br><span class="line">./deviceQuery</span><br></pre></td></tr></table></figure></p><p>显示gpu信息，说明安装成功。</p><p>查看显卡情况：nvidia-smi</p><h2 id="4-配置cuDNN"><a href="#4-配置cuDNN" class="headerlink" title="4. 配置cuDNN"></a>4. 配置cuDNN</h2><p>官网下载：<a href="https://developer.nvidia.com/rdp/cudnn-download" target="_blank" rel="noopener">https://developer.nvidia.com/rdp/cudnn-download</a></p><p>注册账号之后就可以下载啦。(参考文献1下载的5.1，安装6.0没试）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">cd Downloads/cuda</span><br><span class="line"></span><br><span class="line">sudo cp -a include/cudnn.h /usr/local/cuda/include/ # 复制头文件</span><br><span class="line"></span><br><span class="line">cd ./lib64</span><br><span class="line"></span><br><span class="line">sudo cp -a lib* /usr/local/cuda/lib64/ #复制动态链接库</span><br><span class="line"></span><br><span class="line">cd /usr/local/cuda/lib64/</span><br><span class="line"></span><br><span class="line">sudo rm -rf libcudnn.so libcudnn.so.5 #删除原有动态文件</span><br><span class="line"></span><br><span class="line">sudo ln -s libcudnn.so.5.1.5 libcudnn.so.5 #生成软衔接</span><br><span class="line"></span><br><span class="line">sudo ln -s libcudnn.so.5 libcudnn.so #生成软链接</span><br></pre></td></tr></table></figure></p><h2 id="5-tensorflow-gpu-and-keras"><a href="#5-tensorflow-gpu-and-keras" class="headerlink" title="5. tensorflow-gpu and keras"></a>5. tensorflow-gpu and keras</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sudo pip install -U --pre pip setuptools wheel</span><br><span class="line"></span><br><span class="line">sudo pip install -U --pre numpy scipy matplotlib scikit-learn scikit-image</span><br><span class="line"></span><br><span class="line">sudo pip install -U --pre tensorflow-gpu==1.2</span><br><span class="line"></span><br><span class="line">sudo pip install -U --pre keras</span><br></pre></td></tr></table></figure><blockquote><p>注：sudo pip install -U –pre tensorflow-gpu==1.2 , 若没有指定版本，则下载的是最新的版本，我在安装过程中出现以下了问题：</p><ol><li>gpu=1.5 ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory </li><li>gpu=1.4 ImportError:libcudnn.so.6: cannot open shared object file: No such file or directory</li></ol><p>所以，最后选择了gpu1.2，测试成功。</p></blockquote><h2 id="6-验证："><a href="#6-验证：" class="headerlink" title="6. 验证："></a>6. 验证：</h2><h3 id="6-1-简单测试"><a href="#6-1-简单测试" class="headerlink" title="6.1 简单测试"></a>6.1 简单测试</h3><p>首先关闭所有打开的终端并打开一个新的终端。</p><p>将目录（cd）更改为系统中除调用configure命令的tensorflow子目录之外的任何目录。</p><p>调用python：在命令行输入python<br>输入以下短程序：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf </span><br><span class="line">hello = tf.constant(&apos;Hello,TensorFlow!&apos;)</span><br><span class="line">sess = tf.Session()</span><br><span class="line">print(sess.run(hello))</span><br></pre></td></tr></table></figure></p><p>你应该看到“你好，TensorFlow！”。恭喜！<br>您也可以输入<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(tf.__version__)</span><br></pre></td></tr></table></figure></p><p>查看安装的TensorFlow的版本。</p><h3 id="6-2官网给出的测试："><a href="#6-2官网给出的测试：" class="headerlink" title="6.2官网给出的测试："></a>6.2官网给出的测试：</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/fchollet/keras.git</span><br><span class="line"></span><br><span class="line">cd keras/examples/</span><br><span class="line"></span><br><span class="line">python mnist_mlp.py</span><br></pre></td></tr></table></figure><p>我的测试结果如下:<br><img src="https://github.com/fyingzhu/Markdown_photo/blob/master/InstallTool/2018013003.jpg?raw=true" alt=""><br><img src="https://github.com/fyingzhu/Markdown_photo/blob/master/InstallTool/2018013002.jpg?raw=true" alt=""></p><p>可以看到，启用了device(/gpu:0)</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ol><li><a href="http://blog.csdn.net/u013502004/article/details/72876134" target="_blank" rel="noopener">双显卡 ubuntu16.04 安装 NVIDIA驱动 + CUDA + cuDNN + tensorflow-gpu + keras</a></li><li><a href="http://wiki.ubuntu.org.cn/NVIDIA" target="_blank" rel="noopener">http://wiki.ubuntu.org.cn/NVIDIA</a></li><li><p><a href="http://blog.csdn.net/silent56_th/article/details/77587792" target="_blank" rel="noopener">tensorflow安装所遇问题：libcudnn.so.6:cannot open sharedobject file: No such file or directory</a></p></li><li><p><a href=""></a></p></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://github.com/fyingzhu/Markdown_photo/blob/master/blog/20180130001.jpg?raw=true&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;font color=&quot;red&quot;&gt;写在前面，一路安装走来，遇到很多TensorFlow、cuda、cudnn版本不兼容匹配的，后来，我找到了&lt;a href=&quot;https://www.nvidia.com/en-us/data-center/gpu-accelerated-applications/tensorflow/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;NVIDIA官方系统配置&lt;/a&gt; ，可以按照这个来配置，避免多走弯路。&lt;/font&gt;

&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;环境：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ubuntu 16.04 64bit&lt;/li&gt;
&lt;li&gt;&lt;p&gt;显卡：NVIDIA Tesla k40m + 集成显卡&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;注：在&lt;a href=&quot;http://www.nvidia.com/Download/index.aspx?lang=en-us&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;NVIDIA DriverDownloads&lt;/a&gt;查找的最新为384.66，系统配置如下：&lt;br&gt;&lt;img src=&quot;https://github.com/fyingzhu/Markdown_photo/blob/master/InstallTool/2018013001.jpg?raw=true&quot; alt=&quot;系统配置&quot;&gt;&lt;/p&gt;
&lt;font color=&quot;red&quot;&gt; 但是，安装不成功！后选择375.66成功&lt;/font&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;驱动：nvidia 375.66&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;软件：cuda8.0 + cuDNN5.1&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://fyingzhu.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="环境配置" scheme="http://fyingzhu.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
    
    
      <category term="ubuntu16.04" scheme="http://fyingzhu.com/tags/ubuntu16-04/"/>
    
      <category term="CUDA" scheme="http://fyingzhu.com/tags/CUDA/"/>
    
      <category term="tensorflow-gpu" scheme="http://fyingzhu.com/tags/tensorflow-gpu/"/>
    
      <category term="keras" scheme="http://fyingzhu.com/tags/keras/"/>
    
  </entry>
  
  <entry>
    <title>利用LSTM进行时间序列预测</title>
    <link href="http://fyingzhu.com/2018/01/24/LSTM%20Neural%20Network%20for%20Time%20Series%20Prediction/"/>
    <id>http://fyingzhu.com/2018/01/24/LSTM Neural Network for Time Series Prediction/</id>
    <published>2018-01-24T09:54:07.000Z</published>
    <updated>2018-01-25T03:46:55.161Z</updated>
    
    <content type="html"><![CDATA[<p><strong>本文基于<a href="http://www.jakob-aungiers.com/articles/a/LSTM-Neural-Network-for-Time-Series-Prediction" target="_blank" rel="noopener">LSTM Neural Network for Time Series Prediction</a></strong></p><hr><p>神经网络是当今机器学习中的新潮流。因此，在基本的神经网络上有过多的课程和教程，从简单的教程到深入描述它们工作的复杂文章。</p><p>对于更深层的网络，对图像分类任务的痴迷似乎也使教程出现在更复杂的卷积神经网络上。如果你做的是这样的事情，是极好的，但对我来说，我并不特别热衷于分类图像。我对时间框架的数据更感兴趣。这就是复发神经网络（RNNs）来的方便（我猜想通过阅读这篇文章你会知道长时间的记忆网络（LSTM）是RNN最受欢迎和最有用的变体，如果不是，有很多有用的文章描述了LSTM，可以先去看看）。<br><a id="more"></a></p><p>现在虽然有很多关于LSTM的公共研究论文和文章，但是我发现几乎所有这些都涉及到他们背后的理论运作和数学，他们所提供的例子并不能真正显示超前预测的能力，根据LSTM时间序列。再次，如果您想知道LSTM的错综复杂的工作原理是极好的，但如果您只是希望获得运行正常运行，则不是理想的。</p><p>那么我将在这里做的是给出一个关于使用LSTM来预测一些时间序列的完整的代码教程，使用Python[2.7]的Keras包。</p><p>友好警告：如果您正在寻找一个从数学和理论的角度来处理LSTM的工作的文章，那么会让你很失望。然而，如果你正在寻找一个有实际编码示例的文章，请继续阅读…</p><p>注意：该项目的完整代码可以在<a href="http://localhost:8888/tree/LoadForecast/LSTM-Neural-Network-for-Time-Series-Prediction-master" target="_blank" rel="noopener">GitHub页面</a>上找到。</p><hr><h2 id="一个简单的正弦波"><a href="#一个简单的正弦波" class="headerlink" title="一个简单的正弦波"></a>一个简单的正弦波</h2><p>我们可以从我们想到最基本的时间序列开始：正弦函数。让我们创建的数据我们需要的LSTM网络训练在这个功能很多振荡模型。我制作了一个excel电子表格，使幅度和频率为1的sin波（给出6.28的角频率），并且我使用该功能获得超过5001个时间段的数据点，时间差值为0.01。结果就像这样。<br><img src="http://www.jakob-aungiers.com/img/article/lstm-neural-network-timeseries/sindata.png" alt="image"><br><strong><em>5001时间段的完整正弦波数据集</em></strong></p><p>为了节省您使这个的麻烦,我已经把数据放到这个CSV，将使用的训练/测试文件在<a href="https://raw.githubusercontent.com/jaungiers/LSTM-Neural-Network-for-Time-Series-Prediction/master/sinwave.csv" target="_blank" rel="noopener">这里</a>。</p><p>现在我们有数据，我们实际试图实现什么？很简单，我们希望LSTM从我们提供的一组窗口数据中学习正弦波，然后希望我们可以要求LSTM来预测这个系列中的下一个N步骤，并且不断地吐出正弦波。</p><p>我们将首先将CSV文件中的数据转换并加载到将提供LSTM的numpy数组。Keras LSTM层的工作方式是采用三维数组（N，W，F），其中N是训练序列的数量，W是序列长度，F是每个序列的特征数。我选择了一个序列长度（读取窗口大小）为50，它允许网络在每一个序列中看到正弦波的形状，因此希望自己能根据接收到的窗口建立一个序列的模式。这些序列本身是滑动窗口，因此每次移动1，导致与先前的窗口经常重叠。<br><img src="http://www.jakob-aungiers.com/img/article/lstm-neural-network-timeseries/sinwindow.png" alt="image"><br><strong><em>长度为50的序列的示例</em></strong></p><p>以下是将训练数据CSV加载到适当形状的numpy数组中的代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data</span><span class="params">(filename, seq_len, normalise_window)</span>:</span></span><br><span class="line">    f = open(filename, <span class="string">'rb'</span>).read()</span><br><span class="line">    data = f.decode().split(<span class="string">'\n'</span>)</span><br><span class="line"></span><br><span class="line">    sequence_length = seq_len + <span class="number">1</span></span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">for</span> index <span class="keyword">in</span> range(len(data) - sequence_length):</span><br><span class="line">        result.append(data[index: index + sequence_length])</span><br><span class="line"></span><br><span class="line">    result = np.array(result)</span><br><span class="line"></span><br><span class="line">    row = round(<span class="number">0.9</span> * result.shape[<span class="number">0</span>])</span><br><span class="line">    train = result[:int(row), :]</span><br><span class="line">    np.random.shuffle(train)</span><br><span class="line">    x_train = train[:, :<span class="number">-1</span>]</span><br><span class="line">    y_train = train[:, <span class="number">-1</span>]</span><br><span class="line">    x_test = result[int(row):, :<span class="number">-1</span>]</span><br><span class="line">    y_test = result[int(row):, <span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line">    x_train = np.reshape(x_train, (x_train.shape[<span class="number">0</span>], x_train.shape[<span class="number">1</span>], <span class="number">1</span>))</span><br><span class="line">    x_test = np.reshape(x_test, (x_test.shape[<span class="number">0</span>], x_test.shape[<span class="number">1</span>], <span class="number">1</span>))  </span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> [x_train, y_train, x_test, y_test]</span><br></pre></td></tr></table></figure><p>接下来我们需要实际构建网络本身。这是简单的部分！至少如果你使用Keras，就像堆积乐高砖一样简单。我使用了[1，50，100，1]的网络结构，其中我们有一个输入层（由一个大小为50的序列组成），其输入具有50个神经元的LSTM层，然后将其馈送到另一个LSTM层，其中100个神经元然后以具有线性激活功能的1个神经元的完全连接的正常层进行馈送，这将用于给出下一个时间步长的预测。</p><p>以下是模型构建函数的代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_model</span><span class="params">(layers)</span>:</span></span><br><span class="line">    model = Sequential()</span><br><span class="line"></span><br><span class="line">    model.add(LSTM(</span><br><span class="line">        input_shape=(layers[<span class="number">1</span>],layers[<span class="number">0</span>]),</span><br><span class="line">        output_dim=layers[<span class="number">1</span>],</span><br><span class="line">        return_sequences=<span class="keyword">True</span>))</span><br><span class="line">    model.add(Dropout(<span class="number">0.2</span>))</span><br><span class="line"></span><br><span class="line">    model.add(LSTM(</span><br><span class="line">        layers[<span class="number">2</span>],</span><br><span class="line">        return_sequences=<span class="keyword">False</span>))</span><br><span class="line">    model.add(Dropout(<span class="number">0.2</span>))</span><br><span class="line"></span><br><span class="line">    model.add(Dense(</span><br><span class="line">        output_dim=layers[<span class="number">3</span>]))</span><br><span class="line">    model.add(Activation(<span class="string">"linear"</span>))</span><br><span class="line"></span><br><span class="line">    start = time.time()</span><br><span class="line">    model.compile(loss=<span class="string">"mse"</span>, optimizer=<span class="string">"rmsprop"</span>)</span><br><span class="line">    print(<span class="string">"&gt; Compilation Time : "</span>, time.time() - start)</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure><p>最后是时候对数据进行网络训练，看看我们得到了什么。我只用了这个LSTM的1个训练时期，这与传统网络不同，传统的网络需要大量的时代来为网络训练大量的训练示例，在这个1个时期，LSTM将循环遍历训练集中的所有序列窗口。如果这个数据具有较少的结构，则需要大量的时代，但是由于这是具有映射到简单函数的可预测模式的正弦波，训练时期将足够好以获得非常好的近似值全功能功能。</p><p>我们将所有这些运行代码放在一个单独的run.py模块中，并运行它：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">epochs  = <span class="number">1</span></span><br><span class="line">seq_len = <span class="number">50</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">'&gt; Loading data... '</span>)</span><br><span class="line"></span><br><span class="line">X_train, y_train, X_test, y_test = lstm.load_data(<span class="string">'sp500.csv'</span>, seq_len, <span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'&gt; Data Loaded. Compiling...'</span>)</span><br><span class="line"></span><br><span class="line">model = lstm.build_model([<span class="number">1</span>, <span class="number">50</span>, <span class="number">100</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">model.fit(</span><br><span class="line">    X_train,</span><br><span class="line">    y_train,</span><br><span class="line">    batch_size=<span class="number">512</span>,</span><br><span class="line">    nb_epoch=epochs,</span><br><span class="line">    validation_split=<span class="number">0.05</span>)</span><br><span class="line"></span><br><span class="line">predicted = lstm.predict_point_by_point(model, X_test)</span><br></pre></td></tr></table></figure><p>如果您是观察者，您将在上面的load_data（）函数中注意到，我们将数据分为训练集/测试集，就像机器学习问题的标准做法。然而，我们需要注意的是我们实际想在时间序列的预测中实现的。</p><p>如果我们使用测试集，我们将运行每个窗口的真实数据，以预测下一个时间步。如果我们只想预测一个时间步，那么这是很好的，但是如果我们想要预测多个时间步，也许想预测任何紧急的趋势或功能（例如sin函数在这种情况下）使用完整的测试集，将意味着我们会预测下一时间步。无论这一预测，随后的步骤和时间，只使用真实的数据为每个时间步。</p><p>您可以在下面的图表中看到，使用这种方法只能预测每个时间点的前一个时间步长：<br><img src="http://www.jakob-aungiers.com/img/article/lstm-neural-network-timeseries/sinpointprediction.png" alt="image"><br><strong><em>epochs</em> = 1, window size = 50</strong></p><p>然而，如果我们想要做出真正的魔法，并预测许多时间步，我们只使用测试数据的第一个窗口作为启动窗口。在每个时间步，我们将窗口后面的最旧的条目弹出，并将下一个时间步长的预测附加到窗口的前面，实质上是将窗口移动，从而缓慢地建立自己的预测，直到窗口充满了预测值（在我们的情况下，由于我们的窗口大小为50，这将在50个时间步长之后发生）。然后，我们无限期地保持这一点，预测下一次对未来时间步长的预测的时间步长，希望看到新趋势。</p><p>下图显示正弦波时间序列，仅从真实测试数据的初始起始窗口预测，然后预测约500步：<br><img src="http://www.jakob-aungiers.com/img/article/lstm-neural-network-timeseries/sinseqprediction.png" alt="image"><br><strong><em>epochs</em> = 1, window size = 50</strong></p><p>通过真实的数据，我们可以看到，只有1个时期和一个相当小的数据训练集，LSTM已经做了很好的预测sin的功能。您可以看到，随着我们预测越来越多的未来，误差幅度会随着以前预测中的错误被越来越多地用于将来的预测而增加。因此，我们看到，LSTM没有得到正确的频率，它越来越多地尝试预测它。然而，由于sin函数是具有零噪声的非常容易的振荡函数，它可以很好的预测它。</p><p>接下来，我们将尝试看看当我们尝试预测更多随机现实世界的数据时会发生什么。。</p><hr><h1 id="一个不那么简单的股票市场"><a href="#一个不那么简单的股票市场" class="headerlink" title="一个不那么简单的股票市场"></a>一个不那么简单的股票市场</h1><p>我们预测了一个精确逐点的几百次的正弦波。那么我们现在可以在股市时间序列上做同样的事情呢？</p><p>好吧，不行</p><blockquote><p><strong>“没有人知道股票会上涨，下跌，横盘还是他妈的圈子” - 马克·汉娜</strong></p></blockquote><p>不幸的是，股票时间序列不是可以映射的函数。它可以更好地描述为随机游走，这使得整个预测的事情相当困难。但是，LSTM如何识别任何潜在的隐藏趋势呢？那我们来看看吧。</p><p>这是一个CSV文件，我在2000年1月至2016年8月期间采取了标准普尔500指数的调整后收盘价。我已经删除了所有内容，使其与我们的正弦波数据完全相同，现在我们将会通过与我们在同一个训练集/测试集的sin波上使用的相同模型运行它。</p><p>然而，我们需要对我们的数据进行一些微小的改变，因为正弦波已经是一个很好的标准化重复模式，它通过网络良好地运行原始数据点。然而，通过网络运行股票指数的调整回报将使优化过程自身失效，并且不会收敛到任何类型的最佳数量。所以为了解决这个问题，我们将采取每个n尺寸的训练/测试数据窗口，并对每个窗口进行归一化，以反映该窗口开始时的百分比变化（因此点i = 0处的数据总是为0）。在预测过程结束时，我们将使用以下等式来归一化和随后解规范化，以便将预测中的真实世界数字：</p><p>n =价格变动的正常化列表[窗口] </p><p>p =调整后的每日回报价格的原始列表[窗口]</p><p>我们在我们的代码中添加了一个<strong>normalise_windows（window_data）</strong> 函数，并更新<strong>了load_data（filename）</strong> 函数，以包括一个条件调用，并取得序列长度并标准化<strong>load_data（filename，seq_len，normalise_window）</strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data</span><span class="params">(filename, seq_len, normalise_window)</span>:</span></span><br><span class="line">    f = open(filename, <span class="string">'rb'</span>).read()</span><br><span class="line">    data = f.decode().split(<span class="string">'\n'</span>)</span><br><span class="line"></span><br><span class="line">    sequence_length = seq_len + <span class="number">1</span></span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">for</span> index <span class="keyword">in</span> range(len(data) - sequence_length):</span><br><span class="line">        result.append(data[index: index + sequence_length])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> normalise_window:</span><br><span class="line">        result = normalise_windows(result)</span><br><span class="line"></span><br><span class="line">    result = np.array(result)</span><br><span class="line"></span><br><span class="line">    row = round(<span class="number">0.9</span> * result.shape[<span class="number">0</span>])</span><br><span class="line">    train = result[:int(row), :]</span><br><span class="line">    np.random.shuffle(train)</span><br><span class="line">    x_train = train[:, :<span class="number">-1</span>]</span><br><span class="line">    y_train = train[:, <span class="number">-1</span>]</span><br><span class="line">    x_test = result[int(row):, :<span class="number">-1</span>]</span><br><span class="line">    y_test = result[int(row):, <span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line">    x_train = np.reshape(x_train, (x_train.shape[<span class="number">0</span>], x_train.shape[<span class="number">1</span>], <span class="number">1</span>))</span><br><span class="line">    x_test = np.reshape(x_test, (x_test.shape[<span class="number">0</span>], x_test.shape[<span class="number">1</span>], <span class="number">1</span>))  </span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> [x_train, y_train, x_test, y_test]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalise_windows</span><span class="params">(window_data)</span>:</span></span><br><span class="line">    normalised_data = []</span><br><span class="line">    <span class="keyword">for</span> window <span class="keyword">in</span> window_data:</span><br><span class="line">        normalised_window = [((float(p) / float(window[<span class="number">0</span>])) - <span class="number">1</span>) <span class="keyword">for</span> p <span class="keyword">in</span> window]</span><br><span class="line">        normalised_data.append(normalised_window)</span><br><span class="line">    <span class="keyword">return</span> normalised_data</span><br></pre></td></tr></table></figure><p>现在已经如上所述归一化了Windows，因此我们现在可以通过我们的LSTM网络运行我们的库存数据。让我们看看它是如何做的：<br><img src="http://www.jakob-aungiers.com/img/article/lstm-neural-network-timeseries/stockpointprediction.png" alt="image"><br><strong><em>epochs = 50, window size = 50</em></strong></p><p>如上所述在单个逐点预测中运行数据可以很好地匹配回报。但这是欺骗性的！为什么？那么如果你看得更紧密，预测线就是由单一的预测点组成的，这些预测点在他们之前有整个真实历史窗口。因此，网络不需要太多关于时间序列本身的知识，除了每个下一个点最有可能不会离最后一点太远。所以即使它得到了错误的预测，下一个预测将会因真实的历史而忽视不正确的预测，而再次允许出现错误。</p><p>我们不能看到LSTM的大脑发生了什么，但是我会强调，对于这个本质上是随机游走的预测（我们已经做了一个完全随机的数据行走）是模仿股票指数的外观，而且完全相同的事情也是如此！）是以基本上高斯分布“预测”下一个点，从而允许基本上随机的预测不会从真实的数据中流失太多。</p><p>那么，如果我们想看看在价格走势中是否真的有一些潜在的模式可以辨别，那么我们会怎么看？那么我们会做出与波浪问题相同的事情，让网络预测一系列的点，而不是下一个点。</p><p>我们现在可以看到，与作为一个与真实数据几乎相同的正弦波序列的正弦波不同，我们的股票数据预测非常迅速地收敛于某种平衡。 </p><p>看看我们所运行的两个训练样本的平衡（一个有1个时期，一个具有50个时期），我们可以看到两者之间存在着巨大的差异。这种疯狂的差异似乎与你所期望的完全一致；通常更高的时代将意味着更准确的模型，然而在这种情况下，它几乎看起来好像单个时代模型倾向于通常遵循短时间价格变动的某种逆转。</p><p>我们进一步调查这一点，将我们的预测序列限制到50个未来时间步长，然后每次将启动窗口移动50个，实际上创建了50个时间步长的许多独立序列预测：</p><p>我会在这里诚实地说，上面的图表中的结果令我有点惊讶。我期待能够证明，这将是一个愚蠢的游戏，试图从纯粹的历史价格走势来预测未来价格变动的股票指数（因为有这么多潜在因素影响每日价格波动;从基础公司的基本因素，宏观事件，投资者情绪和市场噪音…）然而，检查上面非常有限的测试的预测，我们可以看到，对于很多运动，特别是大型运动，似乎有很大的共识模型预测和随后的价格走势。</p><p>我会在这里放一个他妈的大警告标志！为什么上述“有希望的”图可能是错误的，有很多原因。抽样错误，纯粹的运气在一个小的样本大小…这个图表中没有什么应该采取面值，盲目追随一个钱吸吮坑没有一些彻底和广泛的一系列的backtests（这超出了本文的范围）。你已经被警告了</p><p>实际上，当我们看看上面的图表同样的运行，但是时代增加到400（这应该使模型模式准确），我们看到，实际上现在只是尝试是预测几乎每个时间段的向上的动力！</p><p>然而，我希望你们所有渴望的年轻人都学会了什么使得LSTM网络成为可能的基础，以及如何使用它来预测和映射时间序列，以及这样做的潜在缺陷。</p><p>LSTM使用目前在文字预测，AI聊天应用程序，自驾车等众多领域都很丰富。希望本文扩展了在时间序列方法中使用LSTM的实际应用，您已经发现它很有用。</p><p>为了完整，下面是您可以在GitHub页面上找到的完整项目代码：</p><p>为了参考，我用于运行我的神经网络模型的机器是我强烈推荐的小米Mi笔记本电脑13，因为它具有内置的Nvidia GeForce 940MX显卡，可以与Tensorflow GPU版本一起加速并发模型像LSTM。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;本文基于&lt;a href=&quot;http://www.jakob-aungiers.com/articles/a/LSTM-Neural-Network-for-Time-Series-Prediction&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;LSTM Neural Network for Time Series Prediction&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;神经网络是当今机器学习中的新潮流。因此，在基本的神经网络上有过多的课程和教程，从简单的教程到深入描述它们工作的复杂文章。&lt;/p&gt;
&lt;p&gt;对于更深层的网络，对图像分类任务的痴迷似乎也使教程出现在更复杂的卷积神经网络上。如果你做的是这样的事情，是极好的，但对我来说，我并不特别热衷于分类图像。我对时间框架的数据更感兴趣。这就是复发神经网络（RNNs）来的方便（我猜想通过阅读这篇文章你会知道长时间的记忆网络（LSTM）是RNN最受欢迎和最有用的变体，如果不是，有很多有用的文章描述了LSTM，可以先去看看）。&lt;br&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://fyingzhu.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="deep learning" scheme="http://fyingzhu.com/tags/deep-learning/"/>
    
  </entry>
  
  <entry>
    <title>ubuntu16 环境下 TensorFlow serving安装指南</title>
    <link href="http://fyingzhu.com/2018/01/24/ubuntu16%20%E7%8E%AF%E5%A2%83%E4%B8%8B%20TensorFlow%20serving%E5%AE%89%E8%A3%85%E6%8C%87%E5%8D%97/"/>
    <id>http://fyingzhu.com/2018/01/24/ubuntu16 环境下 TensorFlow serving安装指南/</id>
    <published>2018-01-24T09:54:07.000Z</published>
    <updated>2018-01-25T03:32:59.193Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://github.com/fyingzhu/Markdown_photo/blob/master/blog/20180125003.jpg?raw=true" alt="Markdown_photo/blog/20180125003.jpg"></p><h2 id="1-安装bazel"><a href="#1-安装bazel" class="headerlink" title="1. 安装bazel"></a>1. 安装bazel</h2><blockquote><p>安装参考<a href="https://docs.bazel.build/versions/master/install-ubuntu.html" target="_blank" rel="noopener">Install Bazel on Ubuntu</a></p></blockquote><p>采用第一种 <strong>Using Bazel custom APT repository (recommended)</strong> 方法：</p><ol><li>Install JDK 8</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install openjdk-8-jdk</span><br></pre></td></tr></table></figure><ol><li>Add Bazel distribution URI as a package source (one time setup)</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;deb [arch=amd64] http://storage.googleapis.com/bazel-apt stable jdk1.8&quot; | sudo tee /etc/apt/sources.list.d/bazel.list</span><br><span class="line">curl https://bazel.build/bazel-release.pub.gpg | sudo apt-key add -</span><br></pre></td></tr></table></figure><a id="more"></a><ol><li>Install and update Bazel</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update &amp;&amp; sudo apt-get install bazel</span><br></pre></td></tr></table></figure><p>Once installed, you can upgrade to a newer version of Bazel with:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get upgrade bazel</span><br></pre></td></tr></table></figure><h2 id="2-安装gprc"><a href="#2-安装gprc" class="headerlink" title="2. 安装gprc"></a>2. 安装gprc</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo pip install grpcio</span><br></pre></td></tr></table></figure><p>提示没有pip，安装pip</p><h2 id="3-Packages"><a href="#3-Packages" class="headerlink" title="3.Packages"></a>3.Packages</h2><p>To install TensorFlow Serving dependencies, execute the following:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update &amp;&amp; sudo apt-get install -y \</span><br><span class="line">        build-essential \</span><br><span class="line">        curl \</span><br><span class="line">        libcurl3-dev \</span><br><span class="line">        git \</span><br><span class="line">        libfreetype6-dev \</span><br><span class="line">        libpng12-dev \</span><br><span class="line">        libzmq3-dev \</span><br><span class="line">        pkg-config \</span><br><span class="line">        python-dev \</span><br><span class="line">        python-numpy \</span><br><span class="line">        python-pip \</span><br><span class="line">        software-properties-common \</span><br><span class="line">        swig \</span><br><span class="line">        zip \</span><br><span class="line">        zlib1g-dev</span><br></pre></td></tr></table></figure><h2 id="3-从源代码安装克隆TensorFlow-Serving存储库"><a href="#3-从源代码安装克隆TensorFlow-Serving存储库" class="headerlink" title="3. 从源代码安装克隆TensorFlow Serving存储库"></a>3. 从源代码安装克隆TensorFlow Serving存储库</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git clone --recurse-submodules https://github.com/tensorflow/serving</span><br><span class="line">cd serving</span><br></pre></td></tr></table></figure><blockquote><p>clone会非常慢，建议百度加速，我是硬等了3个小时才clone完。 </p></blockquote><p>下一步，配置TensorFlow, 运行：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd tensorflow</span><br><span class="line">./configure</span><br><span class="line">cd ..</span><br></pre></td></tr></table></figure></p><blockquote><p>配置过程中，会有很多选项问你是否需要，根据需要输入y/n即可。不用的尽量填n，否则后面会有很多文件的路径难以配置（LZ遇到的坑：有些文件根本没有，却让你输入路径）。</p><p>配置的第一项是确认python路径，默认的是/usr/bin/python，可以用<br>which python查看当前python的路径。</p></blockquote><h2 id="4-Build"><a href="#4-Build" class="headerlink" title="4. Build"></a>4. Build</h2><p>To build the entire tree, execute:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bazel build -c opt tensorflow_serving/...</span><br></pre></td></tr></table></figure><p>To test your installation, execute:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bazel test -c opt tensorflow_serving/...</span><br></pre></td></tr></table></figure></p><hr><h3 id="注：过程中会遇到的问题及解决方法："><a href="#注：过程中会遇到的问题及解决方法：" class="headerlink" title="注：过程中会遇到的问题及解决方法："></a>注：过程中会遇到的问题及解决方法：</h3><p>国外软件源安装遇到的坑会少很多。。所以请首先更换软件源在安装其他软件吧。</p><ul><li>添加软件源<br>安装完Ubuntu 16.04后 ，更换为国内的软件源：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo gedit /etc/apt/sources.list</span><br></pre></td></tr></table></figure><p>在文件开头添加下面的网易的软件源：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">deb http://mirrors.163.com/ubuntu/ precise-updates main restricted</span><br><span class="line">deb-src http://mirrors.163.com/ubuntu/ precise-updates main restricted</span><br><span class="line">deb http://mirrors.163.com/ubuntu/ precise universe</span><br><span class="line">deb-src http://mirrors.163.com/ubuntu/ precise universe</span><br><span class="line">deb http://mirrors.163.com/ubuntu/ precise-updates universe</span><br><span class="line">deb-src http://mirrors.163.com/ubuntu/ precise-updates universe</span><br><span class="line">deb http://mirrors.163.com/ubuntu/ precise multiverse</span><br><span class="line">deb-src http://mirrors.163.com/ubuntu/ precise multiverse</span><br><span class="line">deb http://mirrors.163.com/ubuntu/ precise-updates multiverse</span><br><span class="line">deb-src http://mirrors.163.com/ubuntu/ precise-updates multiverse</span><br><span class="line">deb http://mirrors.163.com/ubuntu/ precise-backports main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.163.com/ubuntu/ precise-backports main restricted universe multiverse</span><br></pre></td></tr></table></figure><p>更新软件源：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update</span><br></pre></td></tr></table></figure><ul><li>更改文件夹权限</li></ul><p>sudo chmod 777 XXX</p><ul><li>结束当前命令</li></ul><p>ctrl + c</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ol><li><a href="http://blog.csdn.net/liuqz2009/article/details/52087019" target="_blank" rel="noopener">Ubuntu 16.04LTS安装后需要做的事</a></li><li><a href="https://github.com/tensorflow/serving" target="_blank" rel="noopener">https://github.com/tensorflow/serving</a></li><li><a href="https://github.com/grpc/grpc/tree/master/src/python/grpcio" target="_blank" rel="noopener">https://github.com/grpc/grpc/tree/master/src/python/grpcio</a></li><li><a href="https://docs.bazel.build/versions/master/install-ubuntu.html" target="_blank" rel="noopener">Install Bazel on Ubuntu</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://github.com/fyingzhu/Markdown_photo/blob/master/blog/20180125003.jpg?raw=true&quot; alt=&quot;Markdown_photo/blog/20180125003.jpg&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;1-安装bazel&quot;&gt;&lt;a href=&quot;#1-安装bazel&quot; class=&quot;headerlink&quot; title=&quot;1. 安装bazel&quot;&gt;&lt;/a&gt;1. 安装bazel&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;安装参考&lt;a href=&quot;https://docs.bazel.build/versions/master/install-ubuntu.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Install Bazel on Ubuntu&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;采用第一种 &lt;strong&gt;Using Bazel custom APT repository (recommended)&lt;/strong&gt; 方法：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Install JDK 8&lt;/li&gt;
&lt;/ol&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;sudo apt-get install openjdk-8-jdk&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;ol&gt;
&lt;li&gt;Add Bazel distribution URI as a package source (one time setup)&lt;/li&gt;
&lt;/ol&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;echo &amp;quot;deb [arch=amd64] http://storage.googleapis.com/bazel-apt stable jdk1.8&amp;quot; | sudo tee /etc/apt/sources.list.d/bazel.list&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;curl https://bazel.build/bazel-release.pub.gpg | sudo apt-key add -&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://fyingzhu.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="安装调试" scheme="http://fyingzhu.com/tags/%E5%AE%89%E8%A3%85%E8%B0%83%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>my new post</title>
    <link href="http://fyingzhu.com/2018/01/22/my-new-post/"/>
    <id>http://fyingzhu.com/2018/01/22/my-new-post/</id>
    <published>2018-01-22T09:54:07.000Z</published>
    <updated>2018-01-25T03:28:39.297Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://github.com/fyingzhu/Markdown_photo/blob/master/blog/20180125001.jpg?raw=true" alt="Markdown_photo/blog/20180125001.jpg"></p><ul><li><a href="https://www.jianshu.com/p/189fd945f38f" target="_blank" rel="noopener">搭建个人博客-hexo+github详细完整步骤</a></li><li><a href="https://github.com/litten/hexo-theme-yilia" target="_blank" rel="noopener">一个简洁优雅的hexo主题yilia</a></li><li><a href="https://www.jianshu.com/p/465830080ea9" target="_blank" rel="noopener">HEXO+Github,搭建属于自己的博客</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;https://github.com/fyingzhu/Markdown_photo/blob/master/blog/20180125001.jpg?raw=true&quot; alt=&quot;Markdown_photo/blog/20180125001.jpg&quot;
      
    
    </summary>
    
      <category term="杂谈" scheme="http://fyingzhu.com/categories/%E6%9D%82%E8%B0%88/"/>
    
    
      <category term="记事" scheme="http://fyingzhu.com/tags/%E8%AE%B0%E4%BA%8B/"/>
    
  </entry>
  
  <entry>
    <title>我的博客入门</title>
    <link href="http://fyingzhu.com/2018/01/22/%E6%88%91%E7%9A%84%E5%8D%9A%E5%AE%A2%E5%85%A5%E9%97%A8/"/>
    <id>http://fyingzhu.com/2018/01/22/我的博客入门/</id>
    <published>2018-01-22T08:04:27.536Z</published>
    <updated>2018-01-25T03:52:35.760Z</updated>
    
    <content type="html"><![CDATA[<p>欢迎来到我的博客</p><a id="more"></a>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;欢迎来到我的博客&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://fyingzhu.com/2018/01/22/hello-world/"/>
    <id>http://fyingzhu.com/2018/01/22/hello-world/</id>
    <published>2018-01-22T07:18:05.810Z</published>
    <updated>2018-01-22T07:18:05.810Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
    
  </entry>
  
</feed>
